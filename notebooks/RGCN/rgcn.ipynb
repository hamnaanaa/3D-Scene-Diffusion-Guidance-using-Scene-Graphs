{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of a graph `Data(x=[20, 5], edge_index=[2, 20], edge_attr=[20], y=[20])` (A graph with 20 nodes, 20 edges, 6 different edge types and 1 target label per node) is decomposed into\n",
    "\n",
    "- x: Data stored in nodes (here, num_nodes=20 nodes x dim=5 features):\n",
    "\n",
    "```\n",
    "tensor([[ 0.1338,  0.8443, -1.8535,  1.1781, -1.4325],\n",
    "        [ 0.6020,  0.9776,  0.3087, -0.5191, -0.8351],\n",
    "        [-0.1933,  0.7537,  0.5730, -1.6758,  0.7305],\n",
    "        [-0.0866,  0.0894,  1.5008, -0.7608,  0.7714],\n",
    "        [-0.1519,  1.0402, -0.8959,  0.1330, -0.1550],\n",
    "        [ 0.0830,  0.4799, -0.5175,  2.2978, -0.9849],\n",
    "        [ 0.2736,  1.2479, -0.0293, -0.2829,  1.9557],\n",
    "        [-0.9310,  0.2792, -0.5623, -0.4188, -0.5580],\n",
    "        [-0.0870,  0.6735,  0.7130, -0.7389,  1.3117],\n",
    "        [-0.5930, -1.0240, -0.6158,  0.1470, -0.7293],\n",
    "        [ 0.4986, -1.7924,  0.9244,  1.1364,  1.2943],\n",
    "        [ 0.5379,  0.4017,  0.3074, -0.8189,  0.5053],\n",
    "        [ 2.5506,  0.5360, -0.0889, -0.2462, -0.9926],\n",
    "        [ 0.5416, -0.1752, -0.3871, -0.2850,  0.3497],\n",
    "        [-0.3282,  1.2847, -0.3605, -0.6254,  0.5127],\n",
    "        [ 0.1769, -2.4991,  1.4926, -0.4233, -0.9469],\n",
    "        [ 1.2659, -1.5897, -0.6909, -0.0036,  1.1759],\n",
    "        [-0.4856,  0.3826, -0.6284, -0.4664,  0.0383],\n",
    "        [ 0.2546,  1.5097,  1.2746, -0.5847,  1.1207],\n",
    "        [ 0.9572,  0.4619, -0.4879, -0.4740, -0.1182]])\n",
    "```\n",
    "\n",
    "- edge_index: Encodes connections between nodes. It's always (2,num_edges) shape, the first list is source ids and the target ids for connections (here, num_edges=20):\n",
    "\n",
    "```\n",
    "tensor([[ 8,  5, 14,  5,  4, 14, 15,  4, 17, 13, 12, 15, 13, 11, 10, 12, 19, 0, 19, 16],\n",
    "        [ 5,  8, 15,  0, 13,  0,  2, 17,  9, 16,  3, 12, 18,  4,  5, 18, 12, 8, 16, 10]])\n",
    "```\n",
    "\n",
    "- edge_attr: Encodes types of each edge (since we deal with multiple different edge types in RGCN). The shape is therefore (num_edges, num_edge_features=1) here with values [0, num_relations-1].\n",
    "\n",
    "```\n",
    "tensor([3, 2, 0, 3, 4, 5, 2, 1, 5, 3, 5, 0, 0, 4, 2, 2, 4, 1, 1, 5])\n",
    "```\n",
    "\n",
    "- y: target labels with (n_labels=num_nodes,label_dim=1) shape with n_labels=num_nodes since we do node-level labels (graph-level single prediction is also possible) and label_dim=1 since in this toy example we want to have classification (one value per node indicating target class).\n",
    "\n",
    "```\n",
    "tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[20, 5], edge_index=[2, 25], edge_attr=[25], y=[20])\n"
     ]
    }
   ],
   "source": [
    "# Create a mock graph dataset to test how graph data works\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "num_nodes = 20 # num of nodes\n",
    "dim = 5 # dim of node features\n",
    "num_edges = 25 # num of edges\n",
    "num_classes = 2 # num of target classes\n",
    "num_relations = 6 # num of edge types\n",
    "\n",
    "def generate_random_graph():\n",
    "    # --- Initialize nodes ---\n",
    "    x = torch.randn(num_nodes, dim) # creates num_nodes x dim tensor of (random) node features <- TODO: replace with actual node features\n",
    "\n",
    "    # --- Initialize edges --- \n",
    "    edge_index = torch.randint(num_nodes, (2, num_edges)) # creates 2 x num_edges tensor of (random) edges <- TODO: replace with actual edges\n",
    "\n",
    "    # --- Introduce different types of edges ---\n",
    "    edge_attr = torch.randint(num_relations, (num_edges,)) # creates num_edges x 1 tensor of (random) edge types <- TODO: replace with actual edge types\n",
    "\n",
    "    # --- Initialize labels ---\n",
    "    y = torch.randint(num_classes, (num_nodes,)) # creates num_nodes x 1 tensor of (random) labels <- TODO: replace with actual labels\n",
    "\n",
    "    # --- Create a graph ---\n",
    "    graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "    return graph\n",
    "\n",
    "graph = generate_random_graph()\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import RGCNConv\n",
    "from torch import nn\n",
    "\n",
    "class RGCNNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels,\n",
    "        h_channels_list,\n",
    "        out_channels, \n",
    "        num_relations,\n",
    "        num_bases=None, \n",
    "        aggr='mean',\n",
    "        dp_rate=0.1, \n",
    "        bias=True\n",
    "    ):\n",
    "        super(RGCNNet, self).__init__()\n",
    "        self.num_layers = len(h_channels_list) + 1\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(self.num_layers - 1):\n",
    "            in_channels = in_channels if i == 0 else h_channels_list[i - 1]\n",
    "            out_channels = h_channels_list[i]\n",
    "            self.layers += [\n",
    "                RGCNConv(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    num_relations=num_relations,\n",
    "                    num_bases=num_bases,\n",
    "                    aggr=aggr,\n",
    "                    bias=bias\n",
    "                ),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=dp_rate)\n",
    "            ]\n",
    "        self.layers += [\n",
    "            RGCNConv(\n",
    "                in_channels=h_channels_list[-1],\n",
    "                out_channels=out_channels,\n",
    "                num_relations=num_relations,\n",
    "                num_bases=num_bases,\n",
    "                aggr=aggr,\n",
    "                bias=bias\n",
    "            ),\n",
    "            nn.ReLU(inplace=True) # TODO: other final activation function here?\n",
    "        ]\n",
    "        \n",
    "        self.layers = torch.nn.ModuleList(self.layers)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, RGCNConv):\n",
    "                x = layer(x, edge_index, edge_type)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# --- Initialize model ---\n",
    "# num_bases = 6 # num of bases # TODO: experiment with this\n",
    "h_channels_list = [10, 5] # list of hidden layer sizes\n",
    "\n",
    "model = RGCNNet(\n",
    "    in_channels=dim,\n",
    "    h_channels_list=h_channels_list,\n",
    "    out_channels=num_classes,\n",
    "    num_relations=num_relations,\n",
    "    # num_bases=num_bases,\n",
    "    aggr=\"mean\",\n",
    "    dp_rate=0.1,\n",
    "    bias=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize optimizer ---\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "lr = 0.01 # learning rate\n",
    "weight_decay = 5e-4 # weight decay\n",
    "optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# --- Initialize loss function ---\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# --- Initialize scheduler ---\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize train and val loaders ---\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "OVERFIT_BATCH_SIZE = 20\n",
    "train_batch = [generate_random_graph() for _ in range(OVERFIT_BATCH_SIZE)]\n",
    "val_batch = [generate_random_graph() for _ in range(OVERFIT_BATCH_SIZE)]\n",
    "\n",
    "train_loader = DataLoader(train_batch, batch_size=5, shuffle=True)\n",
    "val_loader = DataLoader(val_batch, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Train loss: 1.6954, Val loss: 1.6175\n",
      "Epoch 1 - Train loss: 1.5185, Val loss: 1.4984\n",
      "Epoch 2 - Train loss: 1.3944, Val loss: 1.4113\n",
      "Epoch 3 - Train loss: 1.3103, Val loss: 1.3372\n",
      "Epoch 4 - Train loss: 1.2327, Val loss: 1.2723\n",
      "Epoch 5 - Train loss: 1.1790, Val loss: 1.2205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:00<00:02, 72.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Train loss: 1.1050, Val loss: 1.1762\n",
      "Epoch 7 - Train loss: 1.0577, Val loss: 1.1343\n",
      "Epoch 8 - Train loss: 0.9797, Val loss: 1.0924\n",
      "Epoch 9 - Train loss: 0.9194, Val loss: 1.0509\n",
      "Epoch 10 - Train loss: 0.9050, Val loss: 1.0101\n",
      "Epoch 11 - Train loss: 0.8300, Val loss: 0.9787\n",
      "Epoch 12 - Train loss: 0.7962, Val loss: 0.9537\n",
      "Epoch 13 - Train loss: 0.7689, Val loss: 0.9327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [00:00<00:02, 67.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Train loss: 0.7375, Val loss: 0.9187\n",
      "Epoch 15 - Train loss: 0.7063, Val loss: 0.9115\n",
      "Epoch 16 - Train loss: 0.6942, Val loss: 0.8956\n",
      "Epoch 17 - Train loss: 0.6755, Val loss: 0.8881\n",
      "Epoch 18 - Train loss: 0.6499, Val loss: 0.8834\n",
      "Epoch 19 - Train loss: 0.6448, Val loss: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [00:00<00:02, 70.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Train loss: 0.6186, Val loss: 0.8692\n",
      "Epoch 21 - Train loss: 0.6363, Val loss: 0.8665\n",
      "Epoch 22 - Train loss: 0.6113, Val loss: 0.8617\n",
      "Epoch 23 - Train loss: 0.5908, Val loss: 0.8597\n",
      "Epoch 24 - Train loss: 0.5952, Val loss: 0.8670\n",
      "Epoch 25 - Train loss: 0.5655, Val loss: 0.8770\n",
      "Epoch 26 - Train loss: 0.5554, Val loss: 0.8910\n",
      "Epoch 27 - Train loss: 0.5566, Val loss: 0.8997\n",
      "Epoch 28 - Train loss: 0.5505, Val loss: 0.9076\n",
      "Epoch 29 - Train loss: 0.5494, Val loss: 0.9279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [00:00<00:02, 73.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Train loss: 0.5622, Val loss: 0.9344\n",
      "Epoch 31 - Train loss: 0.5363, Val loss: 0.9377\n",
      "Epoch 32 - Train loss: 0.5413, Val loss: 0.9419\n",
      "Epoch 33 - Train loss: 0.5079, Val loss: 0.9419\n",
      "Epoch 34 - Train loss: 0.5065, Val loss: 0.9497\n",
      "Epoch 35 - Train loss: 0.5232, Val loss: 0.9592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [00:00<00:02, 75.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 - Train loss: 0.5141, Val loss: 0.9688\n",
      "Epoch 37 - Train loss: 0.5072, Val loss: 0.9800\n",
      "Epoch 38 - Train loss: 0.5133, Val loss: 0.9859\n",
      "Epoch 39 - Train loss: 0.5265, Val loss: 0.9930\n",
      "Epoch 40 - Train loss: 0.5251, Val loss: 0.9890\n",
      "Epoch 41 - Train loss: 0.5276, Val loss: 0.9851\n",
      "Epoch 42 - Train loss: 0.5457, Val loss: 0.9851\n",
      "Epoch 43 - Train loss: 0.5126, Val loss: 0.9863\n",
      "Epoch 44 - Train loss: 0.4964, Val loss: 0.9906\n",
      "Epoch 45 - Train loss: 0.4983, Val loss: 0.9975\n",
      "Epoch 46 - Train loss: 0.5036, Val loss: 1.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [00:00<00:01, 77.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 - Train loss: 0.5030, Val loss: 1.0136\n",
      "Epoch 48 - Train loss: 0.4767, Val loss: 1.0204\n",
      "Epoch 49 - Train loss: 0.4723, Val loss: 1.0249\n",
      "Epoch 50 - Train loss: 0.5320, Val loss: 1.0272\n",
      "Epoch 51 - Train loss: 0.4709, Val loss: 1.0324\n",
      "Epoch 52 - Train loss: 0.4799, Val loss: 1.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56/200 [00:00<00:01, 77.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 - Train loss: 0.4789, Val loss: 1.0441\n",
      "Epoch 54 - Train loss: 0.4792, Val loss: 1.0466\n",
      "Epoch 55 - Train loss: 0.4738, Val loss: 1.0487\n",
      "Epoch 56 - Train loss: 0.4913, Val loss: 1.0493\n",
      "Epoch 57 - Train loss: 0.4746, Val loss: 1.0495\n",
      "Epoch 58 - Train loss: 0.4557, Val loss: 1.0502\n",
      "Epoch 59 - Train loss: 0.4699, Val loss: 1.0506\n",
      "Epoch 60 - Train loss: 0.4674, Val loss: 1.0513\n",
      "Epoch 61 - Train loss: 0.4520, Val loss: 1.0520\n",
      "Epoch 62 - Train loss: 0.4804, Val loss: 1.0515\n",
      "Epoch 63 - Train loss: 0.4645, Val loss: 1.0511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 65/200 [00:00<00:01, 78.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 - Train loss: 0.4943, Val loss: 1.0505\n",
      "Epoch 65 - Train loss: 0.4873, Val loss: 1.0509\n",
      "Epoch 66 - Train loss: 0.5139, Val loss: 1.0517\n",
      "Epoch 67 - Train loss: 0.4914, Val loss: 1.0524\n",
      "Epoch 68 - Train loss: 0.4979, Val loss: 1.0533\n",
      "Epoch 69 - Train loss: 0.4612, Val loss: 1.0544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 73/200 [00:00<00:01, 79.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 - Train loss: 0.4645, Val loss: 1.0554\n",
      "Epoch 71 - Train loss: 0.4572, Val loss: 1.0574\n",
      "Epoch 72 - Train loss: 0.4548, Val loss: 1.0588\n",
      "Epoch 73 - Train loss: 0.4808, Val loss: 1.0597\n",
      "Epoch 74 - Train loss: 0.4608, Val loss: 1.0607\n",
      "Epoch 75 - Train loss: 0.4925, Val loss: 1.0615\n",
      "Epoch 76 - Train loss: 0.4658, Val loss: 1.0620\n",
      "Epoch 77 - Train loss: 0.4582, Val loss: 1.0632\n",
      "Epoch 78 - Train loss: 0.4868, Val loss: 1.0634\n",
      "Epoch 79 - Train loss: 0.4880, Val loss: 1.0639\n",
      "Epoch 80 - Train loss: 0.4665, Val loss: 1.0645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 82/200 [00:01<00:01, 79.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 - Train loss: 0.4747, Val loss: 1.0645\n",
      "Epoch 82 - Train loss: 0.4731, Val loss: 1.0644\n",
      "Epoch 83 - Train loss: 0.4412, Val loss: 1.0647\n",
      "Epoch 84 - Train loss: 0.4318, Val loss: 1.0650\n",
      "Epoch 85 - Train loss: 0.4733, Val loss: 1.0653\n",
      "Epoch 86 - Train loss: 0.4734, Val loss: 1.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 91/200 [00:01<00:01, 80.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 - Train loss: 0.4728, Val loss: 1.0658\n",
      "Epoch 88 - Train loss: 0.4558, Val loss: 1.0660\n",
      "Epoch 89 - Train loss: 0.4807, Val loss: 1.0659\n",
      "Epoch 90 - Train loss: 0.4768, Val loss: 1.0661\n",
      "Epoch 91 - Train loss: 0.4999, Val loss: 1.0664\n",
      "Epoch 92 - Train loss: 0.4524, Val loss: 1.0666\n",
      "Epoch 93 - Train loss: 0.4712, Val loss: 1.0668\n",
      "Epoch 94 - Train loss: 0.4936, Val loss: 1.0667\n",
      "Epoch 95 - Train loss: 0.4814, Val loss: 1.0667\n",
      "Epoch 96 - Train loss: 0.5031, Val loss: 1.0667\n",
      "Epoch 97 - Train loss: 0.4693, Val loss: 1.0666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [00:01<00:01, 80.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 - Train loss: 0.4652, Val loss: 1.0664\n",
      "Epoch 99 - Train loss: 0.4841, Val loss: 1.0664\n",
      "Epoch 100 - Train loss: 0.4530, Val loss: 1.0663\n",
      "Epoch 101 - Train loss: 0.4721, Val loss: 1.0662\n",
      "Epoch 102 - Train loss: 0.4510, Val loss: 1.0661\n",
      "Epoch 103 - Train loss: 0.4585, Val loss: 1.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 109/200 [00:01<00:01, 80.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 - Train loss: 0.4719, Val loss: 1.0661\n",
      "Epoch 105 - Train loss: 0.4487, Val loss: 1.0663\n",
      "Epoch 106 - Train loss: 0.4889, Val loss: 1.0665\n",
      "Epoch 107 - Train loss: 0.4770, Val loss: 1.0666\n",
      "Epoch 108 - Train loss: 0.4589, Val loss: 1.0666\n",
      "Epoch 109 - Train loss: 0.4402, Val loss: 1.0667\n",
      "Epoch 110 - Train loss: 0.4599, Val loss: 1.0668\n",
      "Epoch 111 - Train loss: 0.4748, Val loss: 1.0669\n",
      "Epoch 112 - Train loss: 0.4697, Val loss: 1.0670\n",
      "Epoch 113 - Train loss: 0.4471, Val loss: 1.0672\n",
      "Epoch 114 - Train loss: 0.4822, Val loss: 1.0672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 118/200 [00:01<00:01, 80.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 - Train loss: 0.4398, Val loss: 1.0673\n",
      "Epoch 116 - Train loss: 0.4432, Val loss: 1.0674\n",
      "Epoch 117 - Train loss: 0.4340, Val loss: 1.0675\n",
      "Epoch 118 - Train loss: 0.4726, Val loss: 1.0676\n",
      "Epoch 119 - Train loss: 0.4979, Val loss: 1.0676\n",
      "Epoch 120 - Train loss: 0.4751, Val loss: 1.0676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 127/200 [00:01<00:00, 80.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121 - Train loss: 0.4859, Val loss: 1.0676\n",
      "Epoch 122 - Train loss: 0.4847, Val loss: 1.0675\n",
      "Epoch 123 - Train loss: 0.4693, Val loss: 1.0675\n",
      "Epoch 124 - Train loss: 0.4771, Val loss: 1.0675\n",
      "Epoch 125 - Train loss: 0.4452, Val loss: 1.0675\n",
      "Epoch 126 - Train loss: 0.4510, Val loss: 1.0675\n",
      "Epoch 127 - Train loss: 0.4899, Val loss: 1.0675\n",
      "Epoch 128 - Train loss: 0.4487, Val loss: 1.0675\n",
      "Epoch 129 - Train loss: 0.4392, Val loss: 1.0676\n",
      "Epoch 130 - Train loss: 0.4760, Val loss: 1.0676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 136/200 [00:01<00:00, 80.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 - Train loss: 0.4886, Val loss: 1.0676\n",
      "Epoch 132 - Train loss: 0.4530, Val loss: 1.0676\n",
      "Epoch 133 - Train loss: 0.4778, Val loss: 1.0676\n",
      "Epoch 134 - Train loss: 0.4675, Val loss: 1.0676\n",
      "Epoch 135 - Train loss: 0.4773, Val loss: 1.0676\n",
      "Epoch 136 - Train loss: 0.4897, Val loss: 1.0676\n",
      "Epoch 137 - Train loss: 0.4837, Val loss: 1.0676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 145/200 [00:01<00:00, 80.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 - Train loss: 0.4679, Val loss: 1.0676\n",
      "Epoch 139 - Train loss: 0.4520, Val loss: 1.0676\n",
      "Epoch 140 - Train loss: 0.4589, Val loss: 1.0676\n",
      "Epoch 141 - Train loss: 0.4696, Val loss: 1.0676\n",
      "Epoch 142 - Train loss: 0.4667, Val loss: 1.0676\n",
      "Epoch 143 - Train loss: 0.5019, Val loss: 1.0676\n",
      "Epoch 144 - Train loss: 0.4781, Val loss: 1.0676\n",
      "Epoch 145 - Train loss: 0.4715, Val loss: 1.0676\n",
      "Epoch 146 - Train loss: 0.4593, Val loss: 1.0676\n",
      "Epoch 147 - Train loss: 0.4860, Val loss: 1.0676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 154/200 [00:01<00:00, 79.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 - Train loss: 0.4677, Val loss: 1.0676\n",
      "Epoch 149 - Train loss: 0.4893, Val loss: 1.0676\n",
      "Epoch 150 - Train loss: 0.4616, Val loss: 1.0676\n",
      "Epoch 151 - Train loss: 0.4597, Val loss: 1.0677\n",
      "Epoch 152 - Train loss: 0.4746, Val loss: 1.0677\n",
      "Epoch 153 - Train loss: 0.4515, Val loss: 1.0677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 163/200 [00:02<00:00, 80.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154 - Train loss: 0.4399, Val loss: 1.0677\n",
      "Epoch 155 - Train loss: 0.4784, Val loss: 1.0677\n",
      "Epoch 156 - Train loss: 0.4754, Val loss: 1.0677\n",
      "Epoch 157 - Train loss: 0.4925, Val loss: 1.0677\n",
      "Epoch 158 - Train loss: 0.4528, Val loss: 1.0677\n",
      "Epoch 159 - Train loss: 0.4737, Val loss: 1.0677\n",
      "Epoch 160 - Train loss: 0.4781, Val loss: 1.0677\n",
      "Epoch 161 - Train loss: 0.4500, Val loss: 1.0677\n",
      "Epoch 162 - Train loss: 0.4716, Val loss: 1.0677\n",
      "Epoch 163 - Train loss: 0.4651, Val loss: 1.0677\n",
      "Epoch 164 - Train loss: 0.4660, Val loss: 1.0677\n",
      "Epoch 165 - Train loss: 0.4527, Val loss: 1.0677\n",
      "Epoch 166 - Train loss: 0.4769, Val loss: 1.0678\n",
      "Epoch 167 - Train loss: 0.5100, Val loss: 1.0678\n",
      "Epoch 168 - Train loss: 0.4820, Val loss: 1.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 181/200 [00:02<00:00, 78.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 - Train loss: 0.4830, Val loss: 1.0678\n",
      "Epoch 170 - Train loss: 0.4862, Val loss: 1.0678\n",
      "Epoch 171 - Train loss: 0.4638, Val loss: 1.0678\n",
      "Epoch 172 - Train loss: 0.4717, Val loss: 1.0678\n",
      "Epoch 173 - Train loss: 0.4908, Val loss: 1.0678\n",
      "Epoch 174 - Train loss: 0.4581, Val loss: 1.0678\n",
      "Epoch 175 - Train loss: 0.4564, Val loss: 1.0678\n",
      "Epoch 176 - Train loss: 0.4754, Val loss: 1.0678\n",
      "Epoch 177 - Train loss: 0.4437, Val loss: 1.0678\n",
      "Epoch 178 - Train loss: 0.4605, Val loss: 1.0678\n",
      "Epoch 179 - Train loss: 0.4572, Val loss: 1.0678\n",
      "Epoch 180 - Train loss: 0.4642, Val loss: 1.0679\n",
      "Epoch 181 - Train loss: 0.4991, Val loss: 1.0679\n",
      "Epoch 182 - Train loss: 0.4607, Val loss: 1.0679\n",
      "Epoch 183 - Train loss: 0.4943, Val loss: 1.0679\n",
      "Epoch 184 - Train loss: 0.4692, Val loss: 1.0679\n",
      "Epoch 185 - Train loss: 0.4677, Val loss: 1.0679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 190/200 [00:02<00:00, 78.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186 - Train loss: 0.4647, Val loss: 1.0679\n",
      "Epoch 187 - Train loss: 0.4513, Val loss: 1.0679\n",
      "Epoch 188 - Train loss: 0.4779, Val loss: 1.0679\n",
      "Epoch 189 - Train loss: 0.4757, Val loss: 1.0679\n",
      "Epoch 190 - Train loss: 0.4716, Val loss: 1.0678\n",
      "Epoch 191 - Train loss: 0.4647, Val loss: 1.0678\n",
      "Epoch 192 - Train loss: 0.4596, Val loss: 1.0678\n",
      "Epoch 193 - Train loss: 0.4894, Val loss: 1.0679\n",
      "Epoch 194 - Train loss: 0.4422, Val loss: 1.0679\n",
      "Epoch 195 - Train loss: 0.4643, Val loss: 1.0678\n",
      "Epoch 196 - Train loss: 0.4772, Val loss: 1.0679\n",
      "Epoch 197 - Train loss: 0.4859, Val loss: 1.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 78.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198 - Train loss: 0.4941, Val loss: 1.0678\n",
      "Epoch 199 - Train loss: 0.4824, Val loss: 1.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize tensorboard ---\n",
    "writer = SummaryWriter(log_dir=f'runs/rgcn-overfit-{OVERFIT_BATCH_SIZE}')\n",
    "\n",
    "# --- Setup training loop ---\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 200 # num of epochs\n",
    "best_loss = float('inf') # initialize best loss\n",
    "best_epoch = 0 # initialize best epoch\n",
    "\n",
    "for epoch in (pbar:=tqdm(range(epochs))):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        loss = loss_fn(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "    epoch_loss /= len(train_loader)\n",
    "    writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "    \n",
    "    train_loss = epoch_loss\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    for batch in val_loader:\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        loss = loss_fn(out, batch.y)\n",
    "        epoch_loss += loss.detach().item()\n",
    "    epoch_loss /= len(val_loader)\n",
    "    writer.add_scalar('Loss/val', epoch_loss, epoch)\n",
    "    \n",
    "    val_loss = epoch_loss\n",
    "    \n",
    "    print(f\"Epoch {epoch} - Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # pbar.set_description(f\"Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")\n",
    "    \n",
    "    scheduler.step(epoch_loss)\n",
    "    \n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), 'models/model.pth')\n",
    "    \n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl4cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
