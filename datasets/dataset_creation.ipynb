{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e00e7f",
   "metadata": {},
   "source": [
    "Format of the file:\n",
    "```\n",
    "{\n",
    "  \"scenes\": [\n",
    "    {\n",
    "      \"scene_id\": \"XXXXXXXXX\",\n",
    "      \"scene_matrix\": [20, 309], #  --> (text_emb, location, euler_angles, sizes)\n",
    "      \"graph_objects\": [20, 300], # --> (text_emb)\n",
    "      \"graph_edges\": [2, 50], # --> (o1, o2)\n",
    "      \"graph_relationships\": [50] # --> int\n",
    "    },\n",
    "    {\n",
    "      \"scene_id\": \"YYYYYYYYYYY\",\n",
    "      ...\n",
    "    }\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34805b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "#from text_encoder.py import FastTextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c08c008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the JSON data\n",
    "save_path = '3RScan/data/test.json'\n",
    "\n",
    "# File path to scene folders\n",
    "path_to_scene_folders = '3RScan/data/train'\n",
    "path_to_relationships = '3RScan/data/relationships.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa12bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Text Encoder\n",
    "text_encoder = FastTextEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7558f1",
   "metadata": {},
   "source": [
    "We filter:\n",
    "* max number of objects per scene = 20\n",
    "* allowed object labels: \n",
    "('chair', 'pillow', 'box', 'shelf', 'lamp', 'table', 'door', 'curtain', 'picture', 'cabinet', 'bag', 'light', 'armchair', 'clothes', 'stool', 'kitchen cabinet', 'towel', 'sink', 'blanket', 'commode', 'trash can', 'heater', 'wardrobe', 'bed', 'bench', 'desk', 'sofa', 'monitor', 'basket', 'cushion', 'tv', 'nightstand', 'coffee table', 'mirror', 'bath cabinet', 'rack', 'toilet', 'kitchen counter', 'shoes', 'radiator', 'clutter', 'frame', 'decoration', 'backpack', 'stand', 'bucket', 'counter', 'couch', 'kitchen appliance', 'pc', 'stove', 'tv stand', 'vase', 'side table', 'clothes dryer', 'showcase', 'plate', 'oven', 'refrigerator', 'flower', 'book', 'washing machine', 'plank', 'pillar', 'clock', 'candle', 'bottle', 'telephone', 'bin', 'microwave', 'puf', 'couch table', 'whiteboard', 'laptop', 'shower', 'toilet paper', 'bowl', 'dining chair', 'cupboard', 'roll', 'suitcase', 'desk chair', 'bathtub', 'stairs', 'organizer', 'shower curtain', 'pipe', 'bookshelf', 'bedside table', 'printer', 'boxes', 'toilet brush', 'kitchen towel', 'laundry basket', 'kettle', 'pack', 'stuffed animal', 'carpet', 'soap dispenser', 'ottoman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ca6d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_filter_semseg(scan_folder):\n",
    "    scan_folder_path = os.path.join(path_to_scene_folders, scan_folder)\n",
    "    \n",
    "    # Check if the folder contains semseg.v2.json file\n",
    "    semseg_file = os.path.join(scan_folder_path, 'semseg.v2.json')\n",
    "    if not os.path.isfile(semseg_file):\n",
    "        print(\"This folder has no semseg file: \", scan_folder)\n",
    "\n",
    "    # Read and parse the semseg.v2.json file\n",
    "    with open(semseg_file, 'r') as file:\n",
    "        semseg_data = json.load(file)\n",
    "        \n",
    "    # Define allowed labels\n",
    "    allowed_labels = ['chair', 'pillow', 'box', 'shelf', 'lamp', 'table', 'door', 'curtain', 'picture', 'cabinet', 'bag', 'light', 'armchair', 'clothes', 'stool', 'kitchen cabinet', 'towel', 'sink', 'blanket', 'commode', 'trash can', 'heater', 'wardrobe', 'bed', 'bench', 'desk', 'sofa', 'monitor', 'basket', 'cushion', 'tv', 'nightstand', 'coffee table', 'mirror', 'bath cabinet', 'rack', 'toilet', 'kitchen counter', 'shoes', 'radiator', 'clutter', 'frame', 'decoration', 'backpack', 'stand', 'bucket', 'counter', 'couch', 'kitchen appliance', 'pc', 'stove', 'tv stand', 'vase', 'side table', 'clothes dryer', 'showcase', 'plate', 'oven', 'refrigerator', 'flower', 'book', 'washing machine', 'plank', 'pillar', 'clock', 'candle', 'bottle', 'telephone', 'bin', 'microwave', 'puf', 'couch table', 'whiteboard', 'laptop', 'shower', 'toilet paper', 'bowl', 'dining chair', 'cupboard', 'roll', 'suitcase', 'desk chair', 'bathtub', 'stairs', 'organizer', 'shower curtain', 'pipe', 'bookshelf', 'bedside table', 'printer', 'boxes', 'toilet brush', 'kitchen towel', 'laundry basket', 'kettle', 'pack', 'stuffed animal', 'carpet', 'soap dispenser', 'ottoman']\n",
    "\n",
    "    # Define number of objects\n",
    "    max_N = 5\n",
    "    \n",
    "    seg_groups = semseg_data['segGroups']\n",
    "    \n",
    "    extracted_objects = []\n",
    "    number_objects = 0\n",
    "\n",
    "    # Extract individual objects\n",
    "    for object_data in seg_groups:\n",
    "        obj = {}\n",
    "    \n",
    "        \n",
    "        if (object_data['label'] in allowed_labels) and number_objects < max_N:\n",
    "            obj['label'] = object_data['label']\n",
    "            obj['id'] = object_data['objectId']\n",
    "            obj['location'] = object_data['obb']['centroid']\n",
    "            obj['size'] = object_data['obb']['axesLengths']\n",
    "\n",
    "            normalized_axes = object_data['obb']['normalizedAxes']\n",
    "            rotation_matrix = np.transpose(np.array(normalized_axes).reshape(3, 3))\n",
    "            rotation = Rotation.from_matrix(rotation_matrix)\n",
    "            euler_angles = rotation.as_euler('xyz', degrees=False) # degrees in radians\n",
    "            obj['euler_angles'] = euler_angles\n",
    "            \n",
    "            extracted_objects.append(obj)\n",
    "            number_objects += 1\n",
    "\n",
    "    \n",
    "    return extracted_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe4e92f",
   "metadata": {},
   "source": [
    "What we filter:\n",
    "* max number of relationships\n",
    "* only objects we also have in extracted objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc2ad090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_filter_relationships(scan_folder, extracted_objects):\n",
    "    # Define max. number of edges\n",
    "    max_numb_edges = 10\n",
    "    \n",
    "    allowed_object_ids = {obj['id'] for obj in extracted_objects}\n",
    "    object_vector = np.array(sorted(allowed_object_ids))\n",
    "    \n",
    "    with open(path_to_relationships) as f:\n",
    "        relationships_data = json.load(f)\n",
    "\n",
    "    scene_relationships = relationships_data['scans']\n",
    "\n",
    "    # Find the relationships for the scene with the given id\n",
    "    scene_relationships = [r for r in scene_relationships if r['scan'] == scan_folder]\n",
    "    print('Found {} relationships dictionary for scene {}'.format(len(scene_relationships), scan_folder))\n",
    "    scene_relationships = scene_relationships[0]['relationships']\n",
    "    \n",
    "    # Filter out relationships with objects that are not in the scene_matrix\n",
    "    filtered_relationships = [item for item in scene_relationships if item[0] in allowed_object_ids and item[1] in allowed_object_ids]\n",
    "    print(f\"Found {len(filtered_relationships)} relationships for scene {scan_folder}\")\n",
    "    \n",
    "    # Clip the relationships to max number\n",
    "    clipped_relationships = filtered_relationships[:max_numb_edges]\n",
    "    \n",
    "    # Enumerate objects in relationship data from 0 to ...\n",
    "    mapping_numbers = {number: replacement for replacement, number in enumerate(object_vector, start=0)}\n",
    "    modified_relationships = [[mapping_numbers[obj[0]], mapping_numbers[obj[1]], obj[2], obj[3]] for obj in clipped_relationships]\n",
    "    \n",
    "    # Create object matrix\n",
    "    mapping_labels = {obj['id']: obj['label'] for obj in extracted_objects}\n",
    "    label_vector = [mapping_labels[num] for num in object_vector]\n",
    "    #object_matrix = [text_encoder.encode(label) for label in label_vector]\n",
    "    \n",
    "    # Create edge matrix\n",
    "    edge_matrix_np = np.stack([obj[:2] for obj in modified_relationships]).T\n",
    "    edge_matrix = edge_matrix_np.tolist()\n",
    "\n",
    "    # Create relationship matrix\n",
    "    relationship_vector = [obj[2] for obj in modified_relationships]\n",
    "\n",
    "    #return(object_matrix, )\n",
    "    return(edge_matrix, relationship_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d328dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_scene_matrix(extracted_objects):\n",
    "    '''\n",
    "    # Label Embedding\n",
    "    # Extract the labels from the data\n",
    "    labels = [obj['label'] for obj in extracted_objects]\n",
    "    # Encode the labels using text_encoder.encode()\n",
    "    embeddings = [text_encoder.encode(label) for label in labels]\n",
    "    '''\n",
    "    \n",
    "    # Extract values from the dataset\n",
    "    locations = np.array([obj['location'] for obj in extracted_objects])\n",
    "    euler_angles = np.array([obj['euler_angles'] for obj in extracted_objects])\n",
    "    sizes = np.array([obj['size'] for obj in extracted_objects])\n",
    "\n",
    "    # Create the matrix\n",
    "    stacked_matrix = np.hstack((locations, euler_angles, sizes))\n",
    "    \n",
    "    # Determine the desired number of rows\n",
    "    desired_rows = 5\n",
    "\n",
    "    # Add rows of zeros to each matrix\n",
    "    scene_matrix_np = np.pad(stacked_matrix, [(0, desired_rows - stacked_matrix.shape[0]), (0, 0)], mode='constant')\n",
    "    scene_matrix = scene_matrix_np.tolist()\n",
    "    \n",
    "    return scene_matrix\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6db43a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 relationships dictionary for scene f4f31600-8408-2255-971c-b8c20605563a\n",
      "Found 11 relationships for scene f4f31600-8408-2255-971c-b8c20605563a\n",
      "Found 1 relationships dictionary for scene b8837e3a-57ec-29c6-8b54-d440ca79a11f\n",
      "Found 27 relationships for scene b8837e3a-57ec-29c6-8b54-d440ca79a11f\n",
      "Found 1 relationships dictionary for scene b901681d-e754-293c-8cb3-22aae72dbd42\n",
      "Found 4 relationships for scene b901681d-e754-293c-8cb3-22aae72dbd42\n",
      "{'scenes': [{'scene_id': 'f4f31600-8408-2255-971c-b8c20605563a', 'scene_matrix': [[1.2627571815287477, 3.5120839649475206, -0.13000007808022507, 1.5707963267948968, 0.0, -0.34177145477279264, 0.9916166806447296, 2.719999967813491, 0.5723202049896078], [0.4879435954765271, 3.5344160595066842, -0.4616025621067208, 1.5707963267948968, 0.0, -0.5440600955940643, 0.8708287148221838, 0.4967949726403881, 0.46749919049829614], [0.4083856755914834, 3.5062693147846034, -1.0000000336002597, 1.5707963267948968, 0.0, -0.5518394953826442, 0.783675935902371, 0.859999935477973, 0.7255721641528651], [1.1202349991537242, 1.6253931165734783, -0.27021806462926, 1.5707963267948966, -2.220446049250313e-16, 1.266602548194684, 2.562715772647135, 2.279563912461014, 0.6873274065784616], [-1.4582869233536055, 0.3073965205438316, -0.931165074678178, 1.5707963267948966, 0.0, -0.3514072025724006, 1.8426912811860694, 0.9623300218061351, 0.468365148594828]], 'graph_objects': 2, 'graph_edges': [[1, 2, 2, 2, 3, 3, 3, 3, 4, 4], [2, 3, 3, 4, 2, 2, 4, 4, 2, 3]], 'graph_relationships': [15, 5, 2, 3, 4, 3, 3, 5, 2, 4]}, {'scene_id': 'b8837e3a-57ec-29c6-8b54-d440ca79a11f', 'scene_matrix': [[0.08569919895637992, 0.6931262544781629, -1.02330008655861, 1.5707963267948966, 0.0, 0.8436491658763123, 1.0007478681242306, 0.9066000378146756, 0.6385063255666615], [0.7944193647893271, 2.218390148267107, -1.0309950460271171, 1.5707963267948968, 0.0, 0.42584982156912815, 2.6303319566552883, 0.9619899177106483, 1.8645732422317758], [0.16460553240982512, 1.8810254063027934, -0.7476025932073033, 1.5707963267948968, 0.0, -0.7227520191168862, 0.585404983764318, 0.4447950025321168, 0.3292178835338244], [0.2983951926842129, 2.1523837937474415, -0.7508150450703137, 1.5707963267948966, -2.220446049250313e-16, 1.6996672055201825, 0.9509251425334626, 0.48393999448552716, 0.4102626422355858], [0.802692161983092, 2.475277937737794, -0.7600000610202556, 1.5707963267948968, 0.0, 0.3213660972680441, 1.0928191630961168, 0.4600000278651706, 0.6613404032251579]], 'graph_objects': 2, 'graph_edges': [[2, 3, 4, 0, 0, 1, 1, 2, 2, 2], [1, 1, 1, 1, 1, 0, 0, 3, 3, 4]], 'graph_relationships': [16, 16, 16, 6, 2, 3, 6, 6, 2, 4]}, {'scene_id': 'b901681d-e754-293c-8cb3-22aae72dbd42', 'scene_matrix': [[-0.25248086294573063, -0.4616510860854046, -0.8988951411345225, 1.5707963267948968, 0.0, -0.3201460469451055, 1.368441773913781, 1.0577900173263988, 0.6169491534645826], [-0.21642774758750585, -0.6944978069962093, 0.23188481520373427, 1.570796326794897, 0.0, -0.2266127554228465, 3.617223223180186, 2.6362299329885097, 0.24077994294960056], [-1.6507248698725674, -0.23985234577359593, -0.9066556359084954, 1.5707963267948968, 0.0, -0.3634461298952744, 0.6510210324236889, 1.1266889916355383, 0.36228734641374416], [0.8137602868576415, -1.4902599364684685, 0.0021148751948394384, 1.5707963267948968, 0.0, -0.3221820879913018, 1.47308965447357, 2.915549928347394, 1.0477006596592169], [1.8349841977570565, 1.1493048826478156, -0.25993011497117635, 1.5707963267948968, -2.220446049250313e-16, 1.1652355501465086, 0.7341704656999838, 2.339859969768077, 0.6613254962741857]], 'graph_objects': 2, 'graph_edges': [[0, 2, 2, 4], [2, 0, 4, 2]], 'graph_relationships': [3, 2, 4, 5]}]}\n"
     ]
    }
   ],
   "source": [
    "scenes = []\n",
    "i=0\n",
    "\n",
    "# Iterate over the folders\n",
    "for scan_folder in os.listdir(path_to_scene_folders):\n",
    "    if i>2:\n",
    "        break\n",
    "    if os.path.isdir(os.path.join(path_to_scene_folders, scan_folder)):\n",
    "        scene_data = {}\n",
    "        \n",
    "        extracted_objects = extract_and_filter_semseg(scan_folder)\n",
    "        edge_matrix, relationship_vector = extract_and_filter_relationships(scan_folder, extracted_objects)\n",
    "        #print(extracted_objects)\n",
    "        \n",
    "        scene_data['scene_id'] = scan_folder\n",
    "        scene_data['scene_matrix'] = build_scene_matrix(extracted_objects)\n",
    "        scene_data['graph_objects'] = 2\n",
    "        scene_data['graph_edges'] = edge_matrix\n",
    "        scene_data['graph_relationships'] = relationship_vector\n",
    "        scenes.append(scene_data)\n",
    "    i+=1\n",
    "    #print(scene_data)\n",
    "\n",
    "data = {\"scenes\": scenes}\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99fd3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data as a JSON file\n",
    "with open(save_path, \"w\") as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f8f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
