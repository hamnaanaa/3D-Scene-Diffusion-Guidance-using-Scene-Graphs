{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0394e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# import from guided-diffusion folder\n",
    "from model_alternative import GuidedDiffusionNetwork\n",
    "from ddpm_scheduler import DDPMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f078d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, scenes):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.scenes = scenes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.scenes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        scene = self.scenes[index]\n",
    "        \n",
    "        scene_matrix = torch.tensor(scene[\"scene_matrix\"], dtype=torch.float32)\n",
    "        graph_objects = torch.tensor(scene[\"graph_objects\"], dtype=torch.float32)\n",
    "        graph_edges = torch.tensor(scene[\"graph_edges\"], dtype=torch.long)\n",
    "        graph_relationships = torch.tensor(scene[\"graph_relationships\"], dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'x': scene_matrix,\n",
    "            'obj_cond': graph_objects,\n",
    "            'edge_cond': graph_edges,\n",
    "            'relation_cond': graph_relationships\n",
    "        }\n",
    "\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        x_batch = torch.stack([item['x'] for item in batch], dim=0)\n",
    "        obj_cond_batch = torch.stack([item['obj_cond'] for item in batch], dim=0)\n",
    "        edge_cond_batch = torch.cat([item['edge_cond']+i*20 for i, item in enumerate(batch)], dim=1)\n",
    "        relation_cond_batch = torch.cat([item['relation_cond'] for item in batch], dim=0)\n",
    "\n",
    "        return {\n",
    "            'x': x_batch,\n",
    "            'obj_cond': obj_cond_batch,\n",
    "            'edge_cond': edge_cond_batch,\n",
    "            'relation_cond': relation_cond_batch\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b15e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load data from JSON file\n",
    "with open('test_small.json', 'r') as file:\n",
    "    train_data = json.load(file)['scenes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e15bb3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range matrix for real data\n",
    "location_max = torch.tensor([3.285, 3.93, 0.879])\n",
    "location_min = torch.tensor([-3.334, -2.619, -1.329])\n",
    "\n",
    "normalized_axes_max = torch.ones(9)\n",
    "normalized_axes_min = -torch.ones(9)\n",
    "\n",
    "size_max = torch.tensor([4.878, 2.655, 2.305])\n",
    "size_min = torch.tensor([0.232, 0.14, 0.094])\n",
    "\n",
    "range_max = torch.cat((location_max, normalized_axes_max, size_max), dim=0)\n",
    "range_min = torch.cat((location_min, normalized_axes_min, size_min), dim=0)\n",
    "\n",
    "range_matrix = torch.cat((range_max.unsqueeze(0), range_min.unsqueeze(0)), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c9eba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 3 # num of scenes in batch\n",
    "\n",
    "# Scene hyperparams\n",
    "N = 20 # num of objects in scene\n",
    "D = 15 # dim of objects from the scene\n",
    "\n",
    "# Condition hyperparmas\n",
    "C = 300 # dim of node features\n",
    "R = 23+1 # num of relations\n",
    "\n",
    "hparams = {\n",
    "    'batch_size': B, # num of graphs in batch\n",
    "    'layer_2_dim': 10, # must be a divisor of 300\n",
    "\n",
    "    # --- RGCN hyperparams ---\n",
    "    'rgc_hidden_dims': f\"{()}\", # (C+D, C+D, D),\n",
    "    'rgc_num_bases': 5, # Alternative: None\n",
    "    'rgc_aggr': 'mean',\n",
    "    'rgc_activation': 'tanh',\n",
    "    'rgc_dp_rate': 0.,\n",
    "    'rgc_bias': True,\n",
    "    \n",
    "    # --- Attention hyperparams ---\n",
    "    'attention_self_head_dims': 10,\n",
    "    'attention_num_heads': 3, \n",
    "    'attention_cross_head_dims': 30,\n",
    "    \n",
    "    # Scheduler hyperparams\n",
    "    'scheduler_timesteps': 1000,\n",
    "    'scheduler_loss': 'l2',\n",
    "    'scheduler_beta_schedule': 'cosine',\n",
    "    # Note: not needed for now\n",
    "    # 'scheduler_sampling_timesteps': None,\n",
    "    # \"scheduler_objective\": 'pred_noise',\n",
    "    # 'scheduler_ddim_sampling_eta': 1.0,\n",
    "    # 'scheduler_min_snr_loss_weight': False,\n",
    "    # 'scheduler_min_snr_gamma': 5,\n",
    "    \n",
    "    # Classifier-free guidance parameters\n",
    "    'cfg_cond_drop_prob': 0.,\n",
    "    \n",
    "    # Training and optimizer hyperparams\n",
    "    'epochs': 2000,\n",
    "    'optimizer_lr': 1e-3,\n",
    "    'optimizer_weight_decay': 5e-5,\n",
    "    'lr_scheduler_factor': 0.4,\n",
    "    'lr_scheduler_patience': 30,\n",
    "    'lr_scheduler_minlr': 2e-4,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "099f4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_params = {\n",
    "    \"num_obj\": N,\n",
    "    \"obj_cond_dim\": C\n",
    "}\n",
    "\n",
    "attention_params = {\n",
    "    \"attention_self_head_dim\": hparams['attention_self_head_dims'],\n",
    "    \"attention_num_heads\": hparams['attention_num_heads'],\n",
    "    \"attention_cross_head_dim\": hparams['attention_cross_head_dims']\n",
    "}\n",
    "\n",
    "rgc_params = {\n",
    "    \"rgc_hidden_dims\": hparams['rgc_hidden_dims'],\n",
    "    \"rgc_num_relations\": R,\n",
    "    \"rgc_num_bases\": hparams['rgc_num_bases'],\n",
    "    \"rgc_aggr\": hparams['rgc_aggr'],\n",
    "    \"rgc_activation\": hparams['rgc_activation'],\n",
    "    \"rgc_dp_rate\": hparams['rgc_dp_rate'],\n",
    "    \"rgc_bias\": hparams['rgc_bias']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b60ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sample = torch.randn(N, D)\n",
    "noise = torch.stack([noise_sample] * B, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e29a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "GuidedDiffusionNetwork(\n",
      "  (block1): GuidedDiffusionBlock(\n",
      "    (time_embedding_module): TimeEmbedding(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=14, out_features=15, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=15, out_features=15, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (max_pool): MaxPool1d(kernel_size=(20,), stride=(20,), padding=0, dilation=1, ceil_mode=False)\n",
      "    (rgc_module): RelationalRGCN(\n",
      "      (layers): ModuleList(\n",
      "        (0): RGCNConv(15, 15, num_relations=24)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (self_attention_module): SelfMultiheadAttention(\n",
      "      (qkv_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "      (o_proj): Linear(in_features=30, out_features=15, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (cross_attention_module): CrossMultiheadAttention(\n",
      "      (q_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "      (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "      (o_proj): Linear(in_features=90, out_features=15, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (linear1): Linear(in_features=15, out_features=10, bias=True)\n",
      "  (block2): GuidedDiffusionBlock(\n",
      "    (time_embedding_module): TimeEmbedding(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (max_pool): MaxPool1d(kernel_size=(30,), stride=(30,), padding=0, dilation=1, ceil_mode=False)\n",
      "    (rgc_module): RelationalRGCN(\n",
      "      (layers): ModuleList(\n",
      "        (0): RGCNConv(10, 10, num_relations=24)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (self_attention_module): SelfMultiheadAttention(\n",
      "      (qkv_proj): Linear(in_features=10, out_features=90, bias=False)\n",
      "      (o_proj): Linear(in_features=30, out_features=10, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 10), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (cross_attention_module): CrossMultiheadAttention(\n",
      "      (q_proj): Linear(in_features=10, out_features=90, bias=False)\n",
      "      (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "      (o_proj): Linear(in_features=90, out_features=10, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 10), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (linear2): Linear(in_features=10, out_features=15, bias=True)\n",
      "  (block3): GuidedDiffusionBlock(\n",
      "    (time_embedding_module): TimeEmbedding(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=14, out_features=15, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=15, out_features=15, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (max_pool): MaxPool1d(kernel_size=(20,), stride=(20,), padding=0, dilation=1, ceil_mode=False)\n",
      "    (rgc_module): RelationalRGCN(\n",
      "      (layers): ModuleList(\n",
      "        (0): RGCNConv(15, 15, num_relations=24)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (self_attention_module): SelfMultiheadAttention(\n",
      "      (qkv_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "      (o_proj): Linear(in_features=30, out_features=15, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (cross_attention_module): CrossMultiheadAttention(\n",
      "      (q_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "      (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "      (o_proj): Linear(in_features=90, out_features=15, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (linear3): Linear(in_features=15, out_features=15, bias=True)\n",
      ")\n",
      "DDPM Scheduler:\n",
      "DDPMScheduler(\n",
      "  (model): GuidedDiffusionNetwork(\n",
      "    (block1): GuidedDiffusionBlock(\n",
      "      (time_embedding_module): TimeEmbedding(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=14, out_features=15, bias=True)\n",
      "          (1): Tanh()\n",
      "          (2): Linear(in_features=15, out_features=15, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (max_pool): MaxPool1d(kernel_size=(20,), stride=(20,), padding=0, dilation=1, ceil_mode=False)\n",
      "      (rgc_module): RelationalRGCN(\n",
      "        (layers): ModuleList(\n",
      "          (0): RGCNConv(15, 15, num_relations=24)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (self_attention_module): SelfMultiheadAttention(\n",
      "        (qkv_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "        (o_proj): Linear(in_features=30, out_features=15, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (cross_attention_module): CrossMultiheadAttention(\n",
      "        (q_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "        (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "        (o_proj): Linear(in_features=90, out_features=15, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (linear1): Linear(in_features=15, out_features=10, bias=True)\n",
      "    (block2): GuidedDiffusionBlock(\n",
      "      (time_embedding_module): TimeEmbedding(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "          (1): Tanh()\n",
      "          (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (max_pool): MaxPool1d(kernel_size=(30,), stride=(30,), padding=0, dilation=1, ceil_mode=False)\n",
      "      (rgc_module): RelationalRGCN(\n",
      "        (layers): ModuleList(\n",
      "          (0): RGCNConv(10, 10, num_relations=24)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (self_attention_module): SelfMultiheadAttention(\n",
      "        (qkv_proj): Linear(in_features=10, out_features=90, bias=False)\n",
      "        (o_proj): Linear(in_features=30, out_features=10, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 10), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (cross_attention_module): CrossMultiheadAttention(\n",
      "        (q_proj): Linear(in_features=10, out_features=90, bias=False)\n",
      "        (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "        (o_proj): Linear(in_features=90, out_features=10, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 10), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (linear2): Linear(in_features=10, out_features=15, bias=True)\n",
      "    (block3): GuidedDiffusionBlock(\n",
      "      (time_embedding_module): TimeEmbedding(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=14, out_features=15, bias=True)\n",
      "          (1): Tanh()\n",
      "          (2): Linear(in_features=15, out_features=15, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (max_pool): MaxPool1d(kernel_size=(20,), stride=(20,), padding=0, dilation=1, ceil_mode=False)\n",
      "      (rgc_module): RelationalRGCN(\n",
      "        (layers): ModuleList(\n",
      "          (0): RGCNConv(15, 15, num_relations=24)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (self_attention_module): SelfMultiheadAttention(\n",
      "        (qkv_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "        (o_proj): Linear(in_features=30, out_features=15, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (cross_attention_module): CrossMultiheadAttention(\n",
      "        (q_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "        (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "        (o_proj): Linear(in_features=90, out_features=15, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (linear3): Linear(in_features=15, out_features=15, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3905, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1786, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3013, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "# Not all operations support MPS yet so this option is not available for now\n",
    "# elif torch.has_mps:\n",
    "#     device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "range_matrix = range_matrix.to(device)\n",
    "\n",
    "train_dataset = CustomDataset(train_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=hparams['batch_size'], shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "# --- Instantiate the model\n",
    "model = GuidedDiffusionNetwork(\n",
    "    layer_1_dim=D,\n",
    "    layer_2_dim=hparams['layer_2_dim'],\n",
    "    general_params=general_params,\n",
    "    attention_params=attention_params,\n",
    "    rgc_params=rgc_params,\n",
    "    cond_drop_prob=hparams['cfg_cond_drop_prob']\n",
    ")\n",
    "\n",
    "print(f\"Model:\\n{model}\")\n",
    "\n",
    "scheduler = DDPMScheduler(\n",
    "    model=model,\n",
    "    N=N,\n",
    "    D=D,\n",
    "    range_matrix = range_matrix,\n",
    "    timesteps=hparams['scheduler_timesteps'],\n",
    "    sampling_timesteps=None,\n",
    "    loss_type=hparams['scheduler_loss'],\n",
    "    objective='pred_noise',\n",
    "    beta_schedule=hparams['scheduler_beta_schedule'],\n",
    "    ddim_sampling_eta=1.0,\n",
    "    min_snr_loss_weight=False,\n",
    "    min_snr_gamma=5\n",
    ")\n",
    "\n",
    "print(f\"DDPM Scheduler:\\n{scheduler}\")\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "scheduler = scheduler.to(device)\n",
    "\n",
    "# ---- Training Test\n",
    "for batch in train_dataloader:\n",
    "    x_batch = batch['x'].to(device)\n",
    "    obj_cond_batch = batch['obj_cond'].to(device)\n",
    "    edge_cond_batch = batch['edge_cond'].to(device)\n",
    "    relation_cond_batch = batch['relation_cond'].to(device)\n",
    "\n",
    "    loss = scheduler(x_batch, obj_cond_batch, edge_cond_batch, relation_cond_batch)\n",
    "    print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b480b515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 11:27:23.000498: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "GuidedDiffusionNetwork(\n",
      "  (block1): GuidedDiffusionBlock(\n",
      "    (time_embedding_module): TimeEmbedding(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=14, out_features=15, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=15, out_features=15, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (max_pool): MaxPool1d(kernel_size=(20,), stride=(20,), padding=0, dilation=1, ceil_mode=False)\n",
      "    (rgc_module): RelationalRGCN(\n",
      "      (layers): ModuleList(\n",
      "        (0): RGCNConv(15, 15, num_relations=24)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (self_attention_module): SelfMultiheadAttention(\n",
      "      (qkv_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "      (o_proj): Linear(in_features=30, out_features=15, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (cross_attention_module): CrossMultiheadAttention(\n",
      "      (q_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "      (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "      (o_proj): Linear(in_features=90, out_features=15, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (linear1): Linear(in_features=15, out_features=10, bias=True)\n",
      "  (block2): GuidedDiffusionBlock(\n",
      "    (time_embedding_module): TimeEmbedding(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (max_pool): MaxPool1d(kernel_size=(30,), stride=(30,), padding=0, dilation=1, ceil_mode=False)\n",
      "    (rgc_module): RelationalRGCN(\n",
      "      (layers): ModuleList(\n",
      "        (0): RGCNConv(10, 10, num_relations=24)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (self_attention_module): SelfMultiheadAttention(\n",
      "      (qkv_proj): Linear(in_features=10, out_features=90, bias=False)\n",
      "      (o_proj): Linear(in_features=30, out_features=10, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 10), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (cross_attention_module): CrossMultiheadAttention(\n",
      "      (q_proj): Linear(in_features=10, out_features=90, bias=False)\n",
      "      (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "      (o_proj): Linear(in_features=90, out_features=10, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 10), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (linear2): Linear(in_features=10, out_features=15, bias=True)\n",
      "  (block3): GuidedDiffusionBlock(\n",
      "    (time_embedding_module): TimeEmbedding(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=14, out_features=15, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=15, out_features=15, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (max_pool): MaxPool1d(kernel_size=(20,), stride=(20,), padding=0, dilation=1, ceil_mode=False)\n",
      "    (rgc_module): RelationalRGCN(\n",
      "      (layers): ModuleList(\n",
      "        (0): RGCNConv(15, 15, num_relations=24)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (self_attention_module): SelfMultiheadAttention(\n",
      "      (qkv_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "      (o_proj): Linear(in_features=30, out_features=15, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (cross_attention_module): CrossMultiheadAttention(\n",
      "      (q_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "      (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "      (o_proj): Linear(in_features=90, out_features=15, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (linear3): Linear(in_features=15, out_features=15, bias=True)\n",
      ")\n",
      "DDPM Scheduler:\n",
      "DDPMScheduler(\n",
      "  (model): GuidedDiffusionNetwork(\n",
      "    (block1): GuidedDiffusionBlock(\n",
      "      (time_embedding_module): TimeEmbedding(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=14, out_features=15, bias=True)\n",
      "          (1): Tanh()\n",
      "          (2): Linear(in_features=15, out_features=15, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (max_pool): MaxPool1d(kernel_size=(20,), stride=(20,), padding=0, dilation=1, ceil_mode=False)\n",
      "      (rgc_module): RelationalRGCN(\n",
      "        (layers): ModuleList(\n",
      "          (0): RGCNConv(15, 15, num_relations=24)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (self_attention_module): SelfMultiheadAttention(\n",
      "        (qkv_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "        (o_proj): Linear(in_features=30, out_features=15, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (cross_attention_module): CrossMultiheadAttention(\n",
      "        (q_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "        (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "        (o_proj): Linear(in_features=90, out_features=15, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (linear1): Linear(in_features=15, out_features=10, bias=True)\n",
      "    (block2): GuidedDiffusionBlock(\n",
      "      (time_embedding_module): TimeEmbedding(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "          (1): Tanh()\n",
      "          (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (max_pool): MaxPool1d(kernel_size=(30,), stride=(30,), padding=0, dilation=1, ceil_mode=False)\n",
      "      (rgc_module): RelationalRGCN(\n",
      "        (layers): ModuleList(\n",
      "          (0): RGCNConv(10, 10, num_relations=24)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (self_attention_module): SelfMultiheadAttention(\n",
      "        (qkv_proj): Linear(in_features=10, out_features=90, bias=False)\n",
      "        (o_proj): Linear(in_features=30, out_features=10, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 10), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (cross_attention_module): CrossMultiheadAttention(\n",
      "        (q_proj): Linear(in_features=10, out_features=90, bias=False)\n",
      "        (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "        (o_proj): Linear(in_features=90, out_features=10, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 10), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (linear2): Linear(in_features=10, out_features=15, bias=True)\n",
      "    (block3): GuidedDiffusionBlock(\n",
      "      (time_embedding_module): TimeEmbedding(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=14, out_features=15, bias=True)\n",
      "          (1): Tanh()\n",
      "          (2): Linear(in_features=15, out_features=15, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (max_pool): MaxPool1d(kernel_size=(20,), stride=(20,), padding=0, dilation=1, ceil_mode=False)\n",
      "      (rgc_module): RelationalRGCN(\n",
      "        (layers): ModuleList(\n",
      "          (0): RGCNConv(15, 15, num_relations=24)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (self_attention_module): SelfMultiheadAttention(\n",
      "        (qkv_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "        (o_proj): Linear(in_features=30, out_features=15, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (cross_attention_module): CrossMultiheadAttention(\n",
      "        (q_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "        (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "        (o_proj): Linear(in_features=90, out_features=15, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (linear3): Linear(in_features=15, out_features=15, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████▉                     | 945/2000 [45:32<50:50,  2.89s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 91\u001b[0m\n\u001b[1;32m     88\u001b[0m edge_cond_batch \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_cond\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     89\u001b[0m relation_cond_batch \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelation_cond\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 91\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mscheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj_cond_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_cond_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation_cond_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Backprop\u001b[39;00m\n\u001b[1;32m     94\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/i2dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Guided-3D-Scene-Synthesis-using-DDPMs/guided-diffusion/ddpm_scheduler.py:404\u001b[0m, in \u001b[0;36mDDPMScheduler.forward\u001b[0;34m(self, data, obj_cond, edge_cond, relation_cond, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps, (B,), device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mlong() \n\u001b[1;32m    402\u001b[0m data \u001b[38;5;241m=\u001b[39m DDPMUtils\u001b[38;5;241m.\u001b[39mnormalize_to_neg_one_to_one(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrange_matrix) \n\u001b[0;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Guided-3D-Scene-Synthesis-using-DDPMs/guided-diffusion/ddpm_scheduler.py:370\u001b[0m, in \u001b[0;36mDDPMScheduler.p_losses\u001b[0;34m(self, x_start, t, obj_cond, edge_cond, relation_cond, noise)\u001b[0m\n\u001b[1;32m    366\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_sample(x_start \u001b[38;5;241m=\u001b[39m x_start, t \u001b[38;5;241m=\u001b[39m t, noise \u001b[38;5;241m=\u001b[39m noise)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# predict and take gradient step\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation_cond\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# self.model\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_noise\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    373\u001b[0m     target \u001b[38;5;241m=\u001b[39m noise\n",
      "File \u001b[0;32m~/Guided-3D-Scene-Synthesis-using-DDPMs/guided-diffusion/model_alternative.py:110\u001b[0m, in \u001b[0;36mGuidedDiffusionNetwork.forward\u001b[0;34m(self, x, t, obj_cond, edge_cond, relation_cond, cond_drop_prob)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# --- Step 5: Skip Connection, Block 3\u001b[39;00m\n\u001b[1;32m    109\u001b[0m x_7 \u001b[38;5;241m=\u001b[39m x_6 \u001b[38;5;241m+\u001b[39m x_1\n\u001b[0;32m--> 110\u001b[0m x_8 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# --- Step 6: Linear Layer + Activation\u001b[39;00m\n\u001b[1;32m    113\u001b[0m x_9 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear3(x_8)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/i2dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Guided-3D-Scene-Synthesis-using-DDPMs/guided-diffusion/model_alternative.py:261\u001b[0m, in \u001b[0;36mGuidedDiffusionBlock.forward\u001b[0;34m(self, x, t, obj_cond, edge_cond, relation_cond)\u001b[0m\n\u001b[1;32m    258\u001b[0m self_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attention_module(rgcn_out)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# --- Step 3b: Cross-Attention\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m cross_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgcn_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# --- Step 4: Sum up Parallel Attention Paths\u001b[39;00m\n\u001b[1;32m    264\u001b[0m output \u001b[38;5;241m=\u001b[39m self_out \u001b[38;5;241m+\u001b[39m cross_out\n",
      "File \u001b[0;32m/opt/anaconda3/envs/i2dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Guided-3D-Scene-Synthesis-using-DDPMs/guided-diffusion/attention_layer.py:140\u001b[0m, in \u001b[0;36mCrossMultiheadAttention.forward\u001b[0;34m(self, x, obj_cond)\u001b[0m\n\u001b[1;32m    137\u001b[0m kv \u001b[38;5;241m=\u001b[39m kv\u001b[38;5;241m.\u001b[39mreshape(B, N, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    139\u001b[0m q \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m kv \u001b[38;5;241m=\u001b[39m \u001b[43mkv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m k, v \u001b[38;5;241m=\u001b[39m kv\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Determine value outputs\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/i2dl/lib/python3.10/site-packages/torch/fx/traceback.py:35\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_preserve_node_meta \u001b[38;5;129;01mand\u001b[39;00m stack:\n\u001b[1;32m     32\u001b[0m         current_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(stack)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;129m@compatibility\u001b[39m(is_backward_compatible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_stack\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_preserve_node_meta:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "# Not all operations support MPS yet so this option is not available for now\n",
    "# elif torch.has_mps:\n",
    "#     device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "# --- Load the data\n",
    "range_matrix = range_matrix.to(device)\n",
    "\n",
    "train_dataset = CustomDataset(train_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=hparams['batch_size'], shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "# --- Instantiate the model\n",
    "model = GuidedDiffusionNetwork(\n",
    "    layer_1_dim=D,\n",
    "    layer_2_dim=hparams['layer_2_dim'],\n",
    "    general_params=general_params,\n",
    "    attention_params=attention_params,\n",
    "    rgc_params=rgc_params,\n",
    "    cond_drop_prob=hparams['cfg_cond_drop_prob']\n",
    ")\n",
    "\n",
    "print(f\"Model:\\n{model}\")\n",
    "\n",
    "scheduler = DDPMScheduler(\n",
    "    model=model,\n",
    "    N=N,\n",
    "    D=D,\n",
    "    range_matrix = range_matrix,\n",
    "    timesteps=hparams['scheduler_timesteps'],\n",
    "    sampling_timesteps=None,\n",
    "    loss_type=hparams['scheduler_loss'],\n",
    "    objective='pred_noise',\n",
    "    beta_schedule=hparams['scheduler_beta_schedule'],\n",
    "    ddim_sampling_eta=1.0,\n",
    "    min_snr_loss_weight=False,\n",
    "    min_snr_gamma=5\n",
    ")\n",
    "\n",
    "print(f\"DDPM Scheduler:\\n{scheduler}\")\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "scheduler = scheduler.to(device)\n",
    "\n",
    "\n",
    "# --- Setup training loop ---\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    scheduler.parameters(), \n",
    "    lr=hparams['optimizer_lr'], \n",
    "    weight_decay=hparams['optimizer_weight_decay']\n",
    ")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=hparams['lr_scheduler_factor'], \n",
    "    patience=hparams['lr_scheduler_patience'], \n",
    "    min_lr=hparams['lr_scheduler_minlr']\n",
    ")\n",
    "\n",
    "\n",
    "# --- Initialize tensorboard ---\n",
    "# use timestamp to avoid overwriting previous runs\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "writer = SummaryWriter(log_dir=f'runs/full-DDPM/train-time:{now.strftime(\"%Y-%m-%d-%H:%M:%S\")}')\n",
    "\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(hparams['epochs'])):\n",
    "    scheduler.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    # --- Training loop ---\n",
    "    for batch in train_dataloader:\n",
    "        x_batch = batch['x'].to(device)\n",
    "        obj_cond_batch = batch['obj_cond'].to(device)\n",
    "        edge_cond_batch = batch['edge_cond'].to(device)\n",
    "        relation_cond_batch = batch['relation_cond'].to(device)\n",
    "        \n",
    "        loss = scheduler(x_batch, obj_cond_batch, edge_cond_batch, relation_cond_batch)\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    epoch_loss /= len(train_dataloader)\n",
    "        \n",
    "    lr_scheduler.step(epoch_loss)\n",
    "    writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "    writer.add_scalar('LR', optimizer.param_groups[0]['lr'], epoch)\n",
    "    \n",
    "    # --- Validation loop ---\n",
    "    #with torch.no_grad():\n",
    "        #scheduler.eval()\n",
    "        #epoch_loss = 0\n",
    "        #for batch in val_dataloader:\n",
    "            #x_batch = batch['x'].to(device)\n",
    "            #obj_cond_batch = batch['obj_cond'].to(device)\n",
    "            #edge_cond_batch = batch['edge_cond'].to(device)\n",
    "            #relation_cond_batch = batch['relation_cond'].to(device)\n",
    "            \n",
    "            #loss = scheduler(x_batch, obj_cond_batch, edge_cond_batch, relation_cond_batch)\n",
    "            #epoch_loss += loss.item()\n",
    "            \n",
    "        #epoch_loss /= len(val_dataloader)\n",
    "        #writer.add_scalar('Loss/val', epoch_loss, epoch)\n",
    "        \n",
    "    #if epoch_loss < best_loss:\n",
    "        #best_loss = epoch_loss\n",
    "        #torch.save(model.state_dict(), f'models/best-model.pt')\n",
    "        #print(f\"Saved best model with val loss {best_loss}\")\n",
    "    \n",
    "\n",
    "# log all the hyperparameters and final loss\n",
    "writer.add_hparams(hparams, {'Final loss': epoch_loss})\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01476122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
