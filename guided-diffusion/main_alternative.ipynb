{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0394e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# import from guided-diffusion folder\n",
    "from model_alternative import GuidedDiffusionNetwork\n",
    "from ddpm_scheduler import DDPMScheduler\n",
    "from scenes_dataset import ScenesDataset, DatasetConstants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b15e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load data from JSON file\n",
    "with open('datasets/data/train.json', 'r') as file:\n",
    "    train_data = json.load(file)['scenes']\n",
    "\n",
    "with open('datasets/data/val.json', 'r') as file:\n",
    "    val_data = json.load(file)['scenes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c9eba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 3 # num of scenes in batch\n",
    "\n",
    "# Scene hyperparams\n",
    "N = 20 # num of objects in scene\n",
    "D = 15 # dim of objects from the scene\n",
    "\n",
    "# Condition hyperparmas\n",
    "C = 300 # dim of node features\n",
    "R = 23+1 # num of relations\n",
    "\n",
    "hparams = {\n",
    "    'batch_size': B, # num of graphs in batch\n",
    "    'layer_2_dim': 29, # must be a divisor of 300\n",
    "\n",
    "    # --- RGCN hyperparams ---\n",
    "    'rgc_hidden_dims': f\"{()}\", # (C+D, C+D, D),\n",
    "    'rgc_num_bases': 5, # Alternative: None\n",
    "    'rgc_aggr': 'mean',\n",
    "    'rgc_activation': 'tanh',\n",
    "    'rgc_dp_rate': 0.,\n",
    "    'rgc_bias': True,\n",
    "    \n",
    "    # --- Attention hyperparams ---\n",
    "    'attention_self_head_dims': 10,\n",
    "    'attention_num_heads': 3, \n",
    "    'attention_cross_head_dims': 30,\n",
    "    \n",
    "    # Scheduler hyperparams\n",
    "    'scheduler_timesteps': 1000,\n",
    "    'scheduler_loss': 'l2',\n",
    "    'scheduler_beta_schedule': 'cosine',\n",
    "    # Note: not needed for now\n",
    "    # 'scheduler_sampling_timesteps': None,\n",
    "    # \"scheduler_objective\": 'pred_noise',\n",
    "    # 'scheduler_ddim_sampling_eta': 1.0,\n",
    "    # 'scheduler_min_snr_loss_weight': False,\n",
    "    # 'scheduler_min_snr_gamma': 5,\n",
    "    \n",
    "    # Classifier-free guidance parameters\n",
    "    'cfg_cond_drop_prob': 0.,\n",
    "    \n",
    "    # Training and optimizer hyperparams\n",
    "    'epochs': 2000,\n",
    "    'optimizer_lr': 1e-3,\n",
    "    'optimizer_weight_decay': 5e-5,\n",
    "    'lr_scheduler_factor': 0.8,\n",
    "    'lr_scheduler_patience': 20,\n",
    "    'lr_scheduler_minlr': 8e-5,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099f4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_params = {\n",
    "    \"num_obj\": N,\n",
    "    \"obj_cond_dim\": C\n",
    "}\n",
    "\n",
    "attention_params = {\n",
    "    \"attention_self_head_dim\": hparams['attention_self_head_dims'],\n",
    "    \"attention_num_heads\": hparams['attention_num_heads'],\n",
    "    \"attention_cross_head_dim\": hparams['attention_cross_head_dims']\n",
    "}\n",
    "\n",
    "rgc_params = {\n",
    "    \"rgc_hidden_dims\": hparams['rgc_hidden_dims'],\n",
    "    \"rgc_num_relations\": R,\n",
    "    \"rgc_num_bases\": hparams['rgc_num_bases'],\n",
    "    \"rgc_aggr\": hparams['rgc_aggr'],\n",
    "    \"rgc_activation\": hparams['rgc_activation'],\n",
    "    \"rgc_dp_rate\": hparams['rgc_dp_rate'],\n",
    "    \"rgc_bias\": hparams['rgc_bias']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e30cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample noise for every timestep T in the same shape as the scene [B, N, D]\n",
    "noise = torch.randn(B, N, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b480b515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "GuidedDiffusionNetwork(\n",
      "  (block1): GuidedDiffusionBlock(\n",
      "    (time_embedding_module): TimeEmbedding()\n",
      "    (max_pool): MaxPool1d(kernel_size=(20,), stride=(20,), padding=0, dilation=1, ceil_mode=False)\n",
      "    (rgc_module): RelationalRGCN(\n",
      "      (layers): ModuleList(\n",
      "        (0): RGCNConv(15, 15, num_relations=24)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (self_attention_module): SelfMultiheadAttention(\n",
      "      (qkv_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "      (o_proj): Linear(in_features=30, out_features=15, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (cross_attention_module): CrossMultiheadAttention(\n",
      "      (q_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "      (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "      (o_proj): Linear(in_features=90, out_features=15, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (linear1): Linear(in_features=29, out_features=29, bias=True)\n",
      "  (block2): GuidedDiffusionBlock(\n",
      "    (time_embedding_module): TimeEmbedding()\n",
      "    (max_pool): MaxPool1d(kernel_size=(10,), stride=(10,), padding=0, dilation=1, ceil_mode=False)\n",
      "    (rgc_module): RelationalRGCN(\n",
      "      (layers): ModuleList(\n",
      "        (0): RGCNConv(29, 29, num_relations=24)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (self_attention_module): SelfMultiheadAttention(\n",
      "      (qkv_proj): Linear(in_features=29, out_features=90, bias=False)\n",
      "      (o_proj): Linear(in_features=30, out_features=29, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 29), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (cross_attention_module): CrossMultiheadAttention(\n",
      "      (q_proj): Linear(in_features=29, out_features=90, bias=False)\n",
      "      (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "      (o_proj): Linear(in_features=90, out_features=29, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 29), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (linear2): Linear(in_features=29, out_features=29, bias=True)\n",
      "  (block3): GuidedDiffusionBlock(\n",
      "    (time_embedding_module): TimeEmbedding()\n",
      "    (max_pool): MaxPool1d(kernel_size=(20,), stride=(20,), padding=0, dilation=1, ceil_mode=False)\n",
      "    (rgc_module): RelationalRGCN(\n",
      "      (layers): ModuleList(\n",
      "        (0): RGCNConv(15, 15, num_relations=24)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (self_attention_module): SelfMultiheadAttention(\n",
      "      (qkv_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "      (o_proj): Linear(in_features=30, out_features=15, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (cross_attention_module): CrossMultiheadAttention(\n",
      "      (q_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "      (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "      (o_proj): Linear(in_features=90, out_features=15, bias=False)\n",
      "      (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (linear3): Linear(in_features=29, out_features=29, bias=True)\n",
      "  (linear4): Linear(in_features=29, out_features=15, bias=True)\n",
      ")\n",
      "DDPM Scheduler:\n",
      "DDPMScheduler(\n",
      "  (model): GuidedDiffusionNetwork(\n",
      "    (block1): GuidedDiffusionBlock(\n",
      "      (time_embedding_module): TimeEmbedding()\n",
      "      (max_pool): MaxPool1d(kernel_size=(20,), stride=(20,), padding=0, dilation=1, ceil_mode=False)\n",
      "      (rgc_module): RelationalRGCN(\n",
      "        (layers): ModuleList(\n",
      "          (0): RGCNConv(15, 15, num_relations=24)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (self_attention_module): SelfMultiheadAttention(\n",
      "        (qkv_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "        (o_proj): Linear(in_features=30, out_features=15, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (cross_attention_module): CrossMultiheadAttention(\n",
      "        (q_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "        (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "        (o_proj): Linear(in_features=90, out_features=15, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (linear1): Linear(in_features=29, out_features=29, bias=True)\n",
      "    (block2): GuidedDiffusionBlock(\n",
      "      (time_embedding_module): TimeEmbedding()\n",
      "      (max_pool): MaxPool1d(kernel_size=(10,), stride=(10,), padding=0, dilation=1, ceil_mode=False)\n",
      "      (rgc_module): RelationalRGCN(\n",
      "        (layers): ModuleList(\n",
      "          (0): RGCNConv(29, 29, num_relations=24)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (self_attention_module): SelfMultiheadAttention(\n",
      "        (qkv_proj): Linear(in_features=29, out_features=90, bias=False)\n",
      "        (o_proj): Linear(in_features=30, out_features=29, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 29), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (cross_attention_module): CrossMultiheadAttention(\n",
      "        (q_proj): Linear(in_features=29, out_features=90, bias=False)\n",
      "        (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "        (o_proj): Linear(in_features=90, out_features=29, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 29), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (linear2): Linear(in_features=29, out_features=29, bias=True)\n",
      "    (block3): GuidedDiffusionBlock(\n",
      "      (time_embedding_module): TimeEmbedding()\n",
      "      (max_pool): MaxPool1d(kernel_size=(20,), stride=(20,), padding=0, dilation=1, ceil_mode=False)\n",
      "      (rgc_module): RelationalRGCN(\n",
      "        (layers): ModuleList(\n",
      "          (0): RGCNConv(15, 15, num_relations=24)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (self_attention_module): SelfMultiheadAttention(\n",
      "        (qkv_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "        (o_proj): Linear(in_features=30, out_features=15, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (cross_attention_module): CrossMultiheadAttention(\n",
      "        (q_proj): Linear(in_features=15, out_features=90, bias=False)\n",
      "        (kv_proj): Linear(in_features=300, out_features=180, bias=False)\n",
      "        (o_proj): Linear(in_features=90, out_features=15, bias=False)\n",
      "        (layer_norm): LayerNorm((20, 15), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (linear3): Linear(in_features=29, out_features=29, bias=True)\n",
      "    (linear4): Linear(in_features=29, out_features=15, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<10:37,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.6869428684888792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:00<10:17,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.3448775373091382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:00<10:42,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.2589108509219382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:01<10:27,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.227265632965348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:01<09:59,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.22469961615510223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:02<10:07,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.20778145813498616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:02<10:21,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.2044878453016281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:02<10:21,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.18026175008209283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:03<10:20,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.16927399107616795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:03<10:12,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.15753345323865078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:04<09:48,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.14077337474123505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:04<09:49,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.13741632130705128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2000 [00:05<10:09,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.12230118721230956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2000 [00:06<09:57,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.11615954916000612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2000 [00:06<09:54,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.11536219389724338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 29/2000 [00:08<09:34,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.09076068698128392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 35/2000 [00:10<09:39,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.09047558298719323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 43/2000 [00:12<09:37,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.07517469388794554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 53/2000 [00:15<09:35,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.07448521955323613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 55/2000 [00:16<09:34,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.06409392599016428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 62/2000 [00:18<09:22,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.06320816036005897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 67/2000 [00:19<09:24,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.06299344278594926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 73/2000 [00:21<09:17,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.06215042442329659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 76/2000 [00:22<09:20,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.05618949331851168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 86/2000 [00:25<09:24,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.052687199770911665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 90/2000 [00:26<09:20,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.05228165175750359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 92/2000 [00:27<09:22,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.04248432045386843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 98/2000 [00:28<09:17,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.03727280735692456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 133/2000 [00:39<09:10,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.03207480369813063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 223/2000 [01:05<08:36,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.025768770205149474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 263/2000 [01:16<08:20,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.024917346078994845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 321/2000 [01:33<08:14,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.024267007238885835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 373/2000 [01:49<08:23,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.02258915068920363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 524/2000 [02:34<07:09,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.021564048868873396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 589/2000 [02:53<06:49,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with train loss 0.021390371174697786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 723/2000 [03:32<06:14,  3.41it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 104\u001b[0m\n\u001b[1;32m    102\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    103\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m--> 104\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    105\u001b[0m     epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    107\u001b[0m epoch_loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_dataloader)\n",
      "File \u001b[0;32m~/miniconda3/envs/adl4cv/lib/python3.10/site-packages/torch/optim/optimizer.py:269\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m args\n\u001b[1;32m    268\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m--> 269\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m    270\u001b[0m     \u001b[39m# call optimizer step pre hooks\u001b[39;00m\n\u001b[1;32m    271\u001b[0m     \u001b[39mfor\u001b[39;00m pre_hook \u001b[39min\u001b[39;00m chain(_global_optimizer_pre_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_pre_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    272\u001b[0m         result \u001b[39m=\u001b[39m pre_hook(\u001b[39mself\u001b[39m, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/adl4cv/lib/python3.10/site-packages/torch/autograd/profiler.py:492\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 492\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_enter_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs)\n\u001b[1;32m    493\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/adl4cv/lib/python3.10/site-packages/torch/_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    498\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "# Not all operations support MPS yet so this option is not available for now\n",
    "# elif torch.has_mps:\n",
    "#     device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "# --- Load the data\n",
    "range_matrix = DatasetConstants.get_range_matrix().to(device)\n",
    "\n",
    "train_dataset = ScenesDataset(train_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=hparams['batch_size'], shuffle=True)\n",
    "\n",
    "val_dataset = ScenesDataset(val_data)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=hparams['batch_size'], shuffle=True)\n",
    "\n",
    "# --- Instantiate the model\n",
    "model = GuidedDiffusionNetwork(\n",
    "    layer_1_dim=D,\n",
    "    layer_2_dim=hparams['layer_2_dim'],\n",
    "    general_params=general_params,\n",
    "    attention_params=attention_params,\n",
    "    rgc_params=rgc_params,\n",
    "    cond_drop_prob=hparams['cfg_cond_drop_prob']\n",
    ")\n",
    "\n",
    "print(f\"Model:\\n{model}\")\n",
    "\n",
    "scheduler = DDPMScheduler(\n",
    "    model=model,\n",
    "    N=N,\n",
    "    D=D,\n",
    "    range_matrix = range_matrix[:, C:],\n",
    "    timesteps=hparams['scheduler_timesteps'],\n",
    "    sampling_timesteps=None,\n",
    "    loss_type=hparams['scheduler_loss'],\n",
    "    objective='pred_noise',\n",
    "    beta_schedule=hparams['scheduler_beta_schedule'],\n",
    "    ddim_sampling_eta=1.0,\n",
    "    min_snr_loss_weight=False,\n",
    "    min_snr_gamma=5\n",
    ")\n",
    "\n",
    "print(f\"DDPM Scheduler:\\n{scheduler}\")\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "scheduler = scheduler.to(device)\n",
    "\n",
    "\n",
    "# --- Setup training loop ---\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    scheduler.parameters(), \n",
    "    lr=hparams['optimizer_lr'], \n",
    "    weight_decay=hparams['optimizer_weight_decay']\n",
    ")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=hparams['lr_scheduler_factor'], \n",
    "    patience=hparams['lr_scheduler_patience'], \n",
    "    min_lr=hparams['lr_scheduler_minlr']\n",
    ")\n",
    "\n",
    "\n",
    "# --- Initialize tensorboard ---\n",
    "# use timestamp to avoid overwriting previous runs\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "writer = SummaryWriter(log_dir=f'runs/full-DDPM/train-time:{now.strftime(\"%Y-%m-%d-%H:%M:%S\")}')\n",
    "\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(hparams['epochs'])):\n",
    "    scheduler.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # torch.autograd.set_detect_anomaly(True)\n",
    "    # --- Training loop ---\n",
    "    for batch in train_dataloader:\n",
    "        x_batch = batch.x.to(device)[:, C:]\n",
    "        obj_cond_batch = batch.cond.to(device)\n",
    "        edge_cond_batch = batch.edge_index.to(device)\n",
    "        relation_cond_batch = batch.edge_attr.to(device)\n",
    "        \n",
    "        # X is read as [B*N, D] and needs to be reshaped to [B, N, D]\n",
    "        x_batch = x_batch.view(batch.num_graphs, N, D)\n",
    "        # obj_cond is read as [B*N, C] and needs to be reshaped to [B, N, C]\n",
    "        obj_cond_batch = obj_cond_batch.view(batch.num_graphs, N, C)\n",
    "        \n",
    "        loss = scheduler(x_batch, obj_cond_batch, edge_cond_batch, relation_cond_batch, noise=noise[:batch.num_graphs, :, :])\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    epoch_loss /= len(train_dataloader)\n",
    "        \n",
    "    lr_scheduler.step(epoch_loss)\n",
    "    writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "    writer.add_scalar('LR', optimizer.param_groups[0]['lr'], epoch)\n",
    "    \n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        torch.save(model.state_dict(), f'models/overfit-model.pt')\n",
    "        print(f\"Saved best model with train loss {best_loss}\")\n",
    "    \n",
    "    # --- Validation loop ---\n",
    "    with torch.no_grad():\n",
    "        scheduler.eval()\n",
    "        epoch_loss = 0\n",
    "        for batch in val_dataloader:\n",
    "            x_batch = batch.x.to(device)[:, C:]\n",
    "            obj_cond_batch = batch.cond.to(device)\n",
    "            edge_cond_batch = batch.edge_index.to(device)\n",
    "            relation_cond_batch = batch.edge_attr.to(device)\n",
    "            \n",
    "            # X is read as [B*N, D] and needs to be reshaped to [B, N, D]\n",
    "            x_batch = x_batch.view(batch.num_graphs, N, D)\n",
    "            # obj_cond is read as [B*N, C] and needs to be reshaped to [B, N, C]\n",
    "            obj_cond_batch = obj_cond_batch.view(batch.num_graphs, N, C)\n",
    "            \n",
    "            loss = scheduler(x_batch, obj_cond_batch, edge_cond_batch, relation_cond_batch)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        epoch_loss /= len(val_dataloader)\n",
    "        writer.add_scalar('Loss/val', epoch_loss, epoch)\n",
    "    \n",
    "\n",
    "# log all the hyperparameters and final loss\n",
    "writer.add_hparams(hparams, {'Final loss': epoch_loss})\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01476122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
